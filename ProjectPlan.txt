1.)Core NLP Processing --> Maggie will do this 12/10
2.)KL divergence threshold --> Elliot
	a.) Remove stop words 
	b.) Create an expanded_unigram model on files without stop words
	b.) Run KL divergence on training data w/o stop words
	c.) Run KL divergence on all training data, gather min. max, and average for information dense & non-information dense
	d.) Get threshold of KL divergence
3.) Get the threshold KL divergence
	a.) get the KL divergence for every file in the train data	
		i.) Maintain two separate lists, one for the set of KL divergence values corersponding to information dense files & one for the set of KL divergence values corresponding to the set of non-infomration desne files
		ii.) Get the min, max, and average over both of the lists
		iii.) Determine the threshold from there
4.) Ngram model --> Maggie will do this
	i.) Create an ngram model based on all of the information dense files
	ii.) Function to create an ngram for a given file to compare with cosine similiarty to the information dense baseline

